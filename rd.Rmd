---
title: "glmnetLRC"
subtitle: "Package Reference"
author: Landon Sego
copyright: Battelle Memorial Institute
output:
  packagedocs:
    toc: true
rd_page: true
navpills: |
  <li><a href='index.html'>Docs</a></li>
  <li class="active"><a href='rd.html'>Package Ref</a></li>
  <li><a href='https://github.com/pnnl/glmnetLRC'>Github <i class='fa fa-github'></i></a></li>
brand: |-
  <a href="http://pnnl.github.io">
  <img src='figures/icon.png' alt='PNNL icon' width='30px' height='30px' style='margin-top: -3px;'>
  </a>
---
<h1>Lasso and Elastic-Net Logistic Regression Classification with an Arbitrary Loss Function</h1>

<p><strong>Authors:</strong> (none)</p>
<p><strong>Version:</strong> 0.1.5</p>
<p><strong>License:</strong> file LICENSE</p>

<h4>Description</h4>
<p>Methods for fitting and predicting lasso and elastic-net logistic regression classifiers
(LRC) with an arbitrary loss function for the classification error.</p>

<h4>Depends</h4>
<p>(none)</p>

<h4>Imports</h4>
<p>
glmnet,
plyr,
Smisc</p>

<h4>Suggests</h4>
<p>
parallel,
testthat</p>

<h4>Enhances</h4>
<p>(none)</p>

# Functions



## glmnetLRC

<h3>Construct a lasso or elastic-net logistic regression classifier (LRC) with an arbitrary loss function</h3>

<p class="rd-p">This function extends the <code><a href='http://www.inside-r.org/packages/cran/glmnet/docs/glmnet'>glmnet</a></code> and <code><a href='http://www.inside-r.org/packages/cran/glmnet/docs/cv.glmnet'>cv.glmnet</a></code>
functions from the <a href = 'http://cran.r-project.org/package=glmnet'>glmnet</a>
package. It uses cross validation to identify optimal elastic-net parameters and a
threshold parameter for binary classification, where optimality is defined
by minimizing an arbitrary, user-specified discrete loss function.</p>

<h4>Usage</h4>
<pre class="r"><code>glmnetLRC(truthLabels, predictors, lossMat = "0-1", lossWeight = rep(1,
  NROW(predictors)), alphaVec = seq(0, 1, by = 0.2), tauVec = seq(0.1, 0.9,
  by = 0.05), cvFolds = 5, cvReps = 100, stratify = FALSE,
  masterSeed = 1, nJobs = 1, estimateLoss = FALSE, verbose = FALSE, ...)

printglmnetLRC(x, verbose = TRUE, ...)

plotglmnetLRC(x, ...)

coefglmnetLRC(object, ...)

predictglmnetLRC(object, newdata, truthCol = NULL,
  keepCols = NULL, ...)

missingpredsglmnetLRC(object, newdata, ...)

extractglmnetLRC(object, ...)</code></pre>

<h4>Arguments</h4>
<dl class="rd-dl">
  <dt>truthLabels</dt>
  <dd class="rd-dd">A factor with two levels containing the true labels for each
observation. If it is more desirable to correctly predict one of the two classes over the other,
the second level of this factor should be the class you are most interested in
predicting correctly.</dd>
  <dt>predictors</dt>
  <dd class="rd-dd">A matrix whose columns are the explanatory regression variables.  Note:
factors are not currently supported.  To include a factor variable with <em>n</em> levels, it must be represented
as <em>n-1</em> dummy variables in the matrix.</dd>
  <dt>lossMat</dt>
  <dd class="rd-dd">Either the character string <code>"0-1"</code>, indicating 0-1 loss, or a loss
matrix of class <code>lossMat</code>, produced by <code><a href=#lossmatrix>lossMatrix</a></code>, that specifies
the penalties for classification errors.</dd>
  <dt>lossWeight</dt>
  <dd class="rd-dd">A vector of non-negative weights used to calculate the expected loss. The default value is 1 for
each observation.</dd>
  <dt>alphaVec</dt>
  <dd class="rd-dd">A sequence in [0, 1] designating possible values for the elastic-net mixing parameter,
$\alpha$. A value of $\alpha = 1$ is the lasso penalty, $\alpha = 0$ is the ridge penalty.
Refer to <code><a href=http://www.inside-r.org/packages/cran/glmnet/docs/glmnet>glmnet</a></code> for further information.</dd>
  <dt>tauVec</dt>
  <dd class="rd-dd">A sequence of $\tau$ threshold values in (0, 1) for the
logistic regression classifier. For a new observation, if the predicted probability
that the observation belongs to the second level
of <code>truthLabels</code> exceeds tau, the observation is classified as belonging
to the second level.</dd>
  <dt>cvFolds</dt>
  <dd class="rd-dd">The number of cross validation folds.
<code>cvFolds = length(truthLabels)</code> gives leave-one-out (L.O.O.) cross validation,
in which case <code>cvReps</code> is set to <code>1</code> and <code>stratify</code> is set to <code>FALSE</code>.</dd>
  <dt>cvReps</dt>
  <dd class="rd-dd">The number of cross validation replicates, i.e., the number
of times to repeat the cross validation
by randomly repartitioning the data into folds and estimating the tuning parameters.
For L.O.O. cross validation, this argument is set to <code>1</code> as there can only be one
possible partition of the data.</dd>
  <dt>stratify</dt>
  <dd class="rd-dd">A logical indicating whether stratified sampling should be used
to ensure that observations from
both levels of <code>truthLabels</code> are proportionally present in the cross validation
folds. In other words, stratification attempts to ensure there are sufficient observations
of each level of <code>truthLabels</code> in each training set to fit the model.
Stratification may be required for small or imbalanced data sets.  Note that stratification
is not performed for L.O.O (when <code>cvFolds = length(truthLabels)</code>).</dd>
  <dt>masterSeed</dt>
  <dd class="rd-dd">The random seed used to generate unique (and repeatable) seeds for
each cross validation replicate.</dd>
  <dt>nJobs</dt>
  <dd class="rd-dd">The number of cores on the local host
to use in parallelizing the training.  Parallelization
takes place at the <code>cvReps</code> level, i.e., if <code>cvReps = 1</code>, parallelizing would
do no good, whereas if <code>cvReps = 2</code>, each cross validation replicate would be run
separately in its own thread if <code>nJobs = 2</code>.
Parallelization is executed using <a href = http://pnnl.github.io/docs-Smisc/rd.html#parlapplyw>parLapplyW()</a>
from the <a href = http://pnnl.github.io/docs-Smisc>Smisc</a> package.</dd>
  <dt>estimateLoss</dt>
  <dd class="rd-dd">A logical, set to <code>TRUE</code> to calculate the average loss estimated via
cross validation using the optimized parameters $(\alpha, \lambda, \tau)$ to fit the elastic
net model for each cross validation fold. This can be computationally expensive,
as it requires another cross validation pass through the same partitions of the data, but using only
the optimal parameters to estimate the loss for each cross validation replicate.</dd>
  <dt>verbose</dt>
  <dd class="rd-dd">For <code>glmetLRC</code>, a logical to turn on (or off) messages regarding
the progress of the training algorithm.  For the <code>print</code> method, if set to <code>FALSE</code>, it
will suppress printing information about the <code>glmnetLRC</code> object and only invisibly return
the results.</dd>
  <dt>x</dt>
  <dd class="rd-dd">For the <code>print</code> and <code>plot</code> methods:  an object of class <code>glmnetLRC</code> (returned
by <code>glmnetLRC()</code>), which contains the optimally-trained elastic-net logistic regression classifier.</dd>
  <dt>object</dt>
  <dd class="rd-dd">For the <code>coef</code>, <code>predict</code>, and <code>extract</code> methods:
an object of class <code>glmnetLRC</code> (returned by <code>glmnetLRC()</code>)
which contains the optimally-trained elastic-net logistic regression classifier.</dd>
  <dt>newdata</dt>
  <dd class="rd-dd">A dataframe or matrix containing the new set of observations to
be predicted, as well as an optional column of true labels.
<code>newdata</code> should contain all of the column names that were used
to fit the elastic-net logistic regression classifier.</dd>
  <dt>truthCol</dt>
  <dd class="rd-dd">The column number or column name in <code>newdata</code> that contains the
true labels. Optional.</dd>
  <dt>keepCols</dt>
  <dd class="rd-dd">A numeric vector of column numbers (or a character vector of
column names) that will be kept and returned with the predictions. Optional.</dd>
  <dt>...</dt>
  <dd class="rd-dd">For <code>glmnetLRC()</code>, these are additional arguments to <code><a href=http://www.inside-r.org/packages/cran/glmnet/docs/glmnet>glmnet</a></code> in the <code>glmnet</code> package.
Certain arguments of <code><a href=http://www.inside-r.org/packages/cran/glmnet/docs/glmnet>glmnet</a></code> are reserved by the <code>glmnetLRC</code> package and an error message will make that
clear if they are used.  In particular, arguments that control the behavior of $\alpha$ and $\lambda$ are reserved.
For the <code>plot</code> method, the "..." are additional arguments to the default S3 method <code><a href=http://www.inside-r.org/r-doc/graphics/pairs>pairs</a></code>.  And for
the <code>print</code>, <code>coef</code>, <code>predict</code>, <code>missingpreds</code>, and <code>extract</code> methods, the "..." are ignored.</dd>
</dl>

  <h4>Details</h4>

  <p class="rd-p">For a given partition of the training data, cross validation is
performed to estimate the optimal values of
$\alpha$ (the mixing parameter of the ridge and lasso penalties) and $\lambda$
(the regularization parameter), as well as the optimal threshold, $\tau$,
which is used to dichotomize the probability predictions of the elastic-net
logistic regression model into binary outcomes.
(Specifically, if the probability an observation
belongs to the second level of <code>truthLabels</code> exceeds $\tau$, it is
classified as belonging to that second level).  In this case, optimality is defined
as the set of parameters that minimize the risk, or expected loss, where the
loss function created using <code><a href=#lossmatrix>lossMatrix</a></code>.  The expected loss is calculated such
that each observation in the data receives equal weight</p>

  <p class="rd-p"><code>glmnetLRC()</code> searches for the optimal values of $\alpha$ and $\tau$ by
fitting the elastic-net model at the points of the two-dimensional grid defined by
<code>alphaVec</code> and <code>tauVec</code>.  For each value of $\alpha$, the vector of
$\lambda$ values is selected automatically by <code><a href=http://www.inside-r.org/packages/cran/glmnet/docs/glmnet>glmnet</a></code> according to its default
arguments. The expected loss is calculated for each $(\alpha,\lambda,\tau)$ triple, and the
triple giving rise to the lowest risk designates the optimal model for a given
cross validation partition, or cross validation replicate, of the data.</p>

  <p class="rd-p">This process is repeated <code>cvReps</code> times, where each time a different random
partition of the data is created using its own seed, resulting in another
optimal estimate of $(\alpha,\lambda,\tau)$.  The final estimate of
$(\alpha,\lambda,\tau)$ is given by the respective medians of those estimates.
The final elastic-net logistic regression classfier is given by fitting the regression
coefficients to all the training data using the optimal $(\alpha,\lambda,\tau)$.</p>

  <p class="rd-p">The methodology is discussed in detail in the online
<a href = http://pnnl.github.io/docs-glmnetLRC/index.html#mathematical-details>package documentation</a>.</p>


  <h4>Value</h4>

  <p class="rd-p"><dl>
An object of class <code>glmnetLRC</code>, which
inherits from classes <code>lognet</code> and <code>glmnet</code>.  It contains the
object returned by <code><a href=http://www.inside-r.org/packages/cran/glmnet/docs/glmnet>glmnet</a></code> that has been fit to all the data using
the optimal parameters $(\alpha, \lambda, \tau)$.
It also contains the following additional elements:
<dl>
<dt>lossMat</dt><dd>The loss matrix used as the criteria for selecting optimal tuning parameters</dd></p>

  <p class="rd-p"><dt>parms</dt><dd>A data fame that contains the tuning parameter estimates for $(\alpha, \lambda, \tau)$ that minimize
the expected loss for each cross validation replicate.  Used by the <code>plot</code> method.</dd></p>

  <p class="rd-p"><dt>optimalParms</dt><dd>A named vector that contains the final estimates of $(\alpha, \lambda, \tau)$, calculated as the
element-wise median of <code>parms</code></dd></p>

  <p class="rd-p"><dt>lossEstimates</dt><dd>If <code>estimateLoss = TRUE</code>, this element is a data frame with the expected loss
for each cross validation replicate</dd></p>

  <p class="rd-p"></dl></p>

  <p class="rd-p"></dl></p>


  <h4>Methods (by generic)</h4>

  <p class="rd-p"><ul>
<li> <code>print</code>: Displays the overall optimized values of
$(\alpha, \lambda, \tau)$, with the corresponding degrees of freedom and
deviance for the model fit to all the data using the optimzed parameters.  If <code>estimateLoss = TRUE</code>
when <code>glmnetLRC()</code> was called, the mean and standard deviation of the expected loss are also shown.
In addition, all of this same information is returned invisibly as a matrix. Display of the information
can be suppressed by setting <code>verbose = FALSE</code> in the call to <code>print</code>.</p>

  <p class="rd-p"></li>
<li> <code>plot</code>: Produces a pairs plot of the tuning parameters
$(\alpha, \lambda, \tau)$ and their univariate histograms that
were identified as optimal for each of of the cross validation replicates.
This can provide a sense of the stability of the estimates of the tuning
parameters.</p>

  <p class="rd-p"></li>
<li> <code>coef</code>: Calls the <code>predict</code> method in <code>glmnet</code>
on the fitted glmnet object and returns a named vector of the non-zero elastic-net logistic
regression coefficients using the optimal values of $\alpha$ and $\lambda$.</p>

  <p class="rd-p"></li>
<li> <code>predict</code>: Predict (or classify) new data from an <code>glmnetLRC</code> object.
Returns an object of class <code>LRCpred</code> (which inherits
from <code>data.frame</code>) that contains the predicted probabilities (<code>Prob</code>) and class (<code>predictClass</code>)
for each observation.  The <code>Prob</code> column corresponds to the predicted probability that an observation belongs
to the second level of <code>truthLabels</code>. The columns indicated by <code>truthCol</code> and <code>keepCols</code> are included
if they were requested.  The <code>LRCpred</code> class has two methods:  <code><a href=#summary.lrcpred>summary.LRCpred</a></code> and <code><a href=#plot.lrcpred>plot.LRCpred</a></code>.</p>

  <p class="rd-p"></li>
<li> <code>missingpreds</code>: Identify the set of predictors in a <code>glmnetLRC</code> object that are not
present in <code>newdata</code>. Returns a character vector of the missing predictor names. If no predictors are missing,
it returns <code>character(0)</code>.</p>

  <p class="rd-p"></li>
<li> <code>extract</code>: Extracts the <code>glmnet</code> object that was fit using the optimal parameter estimates of
$(\alpha, \lambda)$.  Returns an object of class <code>"lognet" "glmnet"</code> that can be passed to various
methods available in the <code>glmnet</code> package.
</li>
</ul></p>


  <h4>References</h4>

  <p class="rd-p">Amidan BG, Orton DJ, LaMarche BL, Monroe ME, Moore RJ,
Venzin AM, Smith RD, Sego LH, Tardiff MF, Payne SH. 2014.
Signatures for Mass Spectrometry Data Quality.
Journal of Proteome Research. 13(4), 2215-2222.
<a href = http://pubs.acs.org/doi/abs/10.1021/pr401143e>http://pubs.acs.org/doi/abs/10.1021/pr401143e</a></p>

  <p class="rd-p">Friedman J, Hastie T, Tibshirani R. 2010. Regularization Paths for Generalized
Linear Models via Coordinate Descent. Journal of Statistical Software.
33(1), 1-22.</p>



<h4>Examples</h4>
<pre class="r"><code># Load the VOrbitrap Shewanella QC data from Amidan et al.
data(traindata)

# Here we select the predictor variables
predictors <- as.matrix(traindata[,9:96])

# The logistic regression model requires a binary response
# variable. We will create a factor variable from the
# Curated Quality measurements. Note how we put "poor" as the
# second level in the factor.  This is because the principal
# objective of the classifer is to detect "poor" datasets
response <- factor(traindata$Curated_Quality,
                   levels = c("good", "poor"),
                   labels = c("good", "poor"))

# Specify the loss matrix. The "poor" class is the target of interest.
# The penalty for misclassifying a "poor" item as "good" results in a
# loss of 5.
lM <- lossMatrix(c("good","good","poor","poor"),
                 c("good","poor","good","poor"),
                 c(     0,     1,     5,     0))

# Display the loss matrix
lM

# Train the elastic-net classifier (we don't run it here because it takes a long time)

glmnetLRC_fit <- glmnetLRC(response, predictors, lossMat = lM, estimateLoss = TRUE,
                           nJobs = parallel::detectCores())


# We'll load the precalculated model fit instead
data(glmnetLRC_fit)

# Show the optimal parameter values
print(glmnetLRC_fit)

# Show the coefficients of the optimal model
coef(glmnetLRC_fit)

# Show the plot of all the optimal parameter values for each cross validation replicate
plot(glmnetLRC_fit)

# Extract the 'glmnet' object from the glmnetLRC fit
glmnetObject <- extract(glmnetLRC_fit)

# See how the glmnet methods operate on the object
plot(glmnetObject)

# Look at the coefficients for the optimal lambda
coef(glmnetObject, s = glmnetLRC_fit$optimalParms["lambda"] )

# Load the new observations
data(testdata)

# Use the trained model to make predictions about
# new observations for the response variable.
new <- predict(glmnetLRC_fit, testdata, truthCol = "Curated_Quality", keepCols = 1:2)
head(new)

# Now summarize the performance of the model
summary(new)

# And plot the probability predictions of the model
plot(new, scale = 0.5, legendArgs = list(x = "topright"))

# If predictions are made without an indication of the ground truth,
# the summary is necessarily simpler:
summary(predict(glmnetLRC_fit, testdata))</code></pre>

<h4>See also</h4>

<code><a href=#summary.lrcpred>summary.LRCpred</a></code>, a summary method for objects of class
<code>LRCpred</code>, produced by the <code>predict</code> method.


<h4>Author</h4>

Landon Sego, Alex Venzin




## summary.LRCpred

<h3>Summarize predictions of logistic regression classifier</h3>

<p class="rd-p">Summarize the predicted probabilities of the classifier, and, if possible,
calculate accuracy, sensitivity, specificity, false positive rate, and false
negative rate.</p>

<h4>Usage</h4>
<pre class="r"><code>summaryLRCpred(object, ...)</code></pre>

<h4>Arguments</h4>
<dl class="rd-dl">
  <dt>object</dt>
  <dd class="rd-dd">an object of class <code>LRCpred</code> returned by
<code><a href=#glmnetlrc>predict.glmnetLRC</a></code>.</dd>
  <dt>...</dt>
  <dd class="rd-dd">Arguments passed to <code><a href=http://www.inside-r.org/r-doc/base/print>print</a></code> methods</dd>
</dl>

  <h4>Value</h4>

  <p class="rd-p"><dl>
Prints and invisibly returns the following information:
<ul>
<li> If <code>truthCol</code> was provided in the call to
<code><a href=#glmnetlrc>predict.glmnetLRC</a></code>, the sensitivity, specificity, false negative rate,
false positive rate, and accuracy for the class designated by the second level of
the <code>truthLabels</code> argument
in <code><a href=#glmnetlrc>glmnetLRC</a></code> are calculated.  A summary of the predicted probabilities, according to the true class, is
also provided.</p>

  <p class="rd-p"></li>
<li> If <code>truthCol = NULL</code> in the call to <code><a href=#glmnetlrc>predict.glmnetLRC</a></code>
a tabulation of the number of predictions for each class is shown, along with a summary of the probabilities according
to each predicted class.
</li>
</ul></p>

  <p class="rd-p"></dl></p>




<h4>See also</h4>

See <code><a href=#glmnetlrc>glmnetLRC</a></code> and <code><a href=#glmnetlrc_fit>glmnetLRC_fit</a></code>
for examples.


<h4>Author</h4>

Landon Sego




## plot.LRCpred

<h3>Plot the predictions of logistic regression classifier</h3>


<h4>Usage</h4>
<pre class="r"><code>plotLRCpred(x, pch = c(1, 2), col = c("Blue", "Red"),
  scale = 1, seed = 1, parArgs = NULL, legendArgs = NULL,
  lineArgs = NULL, textArgs = NULL, ...)</code></pre>

<h4>Arguments</h4>
<dl class="rd-dl">
  <dt>x</dt>
  <dd class="rd-dd">an object of class <code>LRCpred</code> returned by <code><a href=#glmnetlrc>predict.glmnetLRC</a></code>.</dd>
  <dt>pch</dt>
  <dd class="rd-dd">A vector of at most length 2 indicating the plotting symbols to be used to differentiate the two true classes.  If
<code>truthCol</code> was not specified in the call to <code><a href=#glmnetlrc>predict.glmnetLRC</a></code>, only the first element is used. This is passed to
<code><a href=http://www.inside-r.org/r-doc/graphics/plot>plot</a></code>.</dd>
  <dt>col</dt>
  <dd class="rd-dd">A vector of at most length 2 indicating the colors of the plotted points in order to differentiate the two true classes.  If
<code>truthCol</code> was not specified in the call to <code><a href=#glmnetlrc>predict.glmnetLRC</a></code>, only the first element is used. This is passed to
<code><a href=http://www.inside-r.org/r-doc/graphics/plot>plot</a></code>.</dd>
  <dt>scale</dt>
  <dd class="rd-dd">A numeric value in (0, 1] that controls scaling of the horizontal axis.  A value of 1 corresponds to the standard,
linear scale.  Values closer to 0 symetrically zoom-in the axis near 0 and 1 while zooming-out the axis in the neighborhood of 0.5.
Values of <code>scale</code> closer to 0 are useful if most of the probability predictions are piled up near 0 and 1.</dd>
  <dt>seed</dt>
  <dd class="rd-dd">Single numeric value that sets the seed for the random jitter of the vertical axis of the plot.</dd>
  <dt>parArgs</dt>
  <dd class="rd-dd">If desired, a list of named arguments that will be passed to <code><a href=http://www.inside-r.org/r-doc/graphics/par>par</a></code> which is called prior to making the plot.</dd>
  <dt>legendArgs</dt>
  <dd class="rd-dd">If desired, a list of named arguments that will be passed to <code><a href=http://www.inside-r.org/r-doc/graphics/legend>legend</a></code>. If
<code>truthCol</code> was not specified in the call to <code><a href=#glmnetlrc>predict.glmnetLRC</a></code>, no legend is drawn.</dd>
  <dt>lineArgs</dt>
  <dd class="rd-dd">If desired, a list of named arguments that will be passed to <code><a href=http://www.inside-r.org/r-doc/graphics/abline>abline</a></code> governing the vertical line that
indicates the value of $\tau$.</dd>
  <dt>textArgs</dt>
  <dd class="rd-dd">If desired, a list of named arguments that will be passed to <code><a href=http://www.inside-r.org/r-doc/graphics/text>text</a></code> governing the text indicating the
value of $\tau$.</dd>
  <dt>...</dt>
  <dd class="rd-dd">Arguments passed to <code><a href=http://www.inside-r.org/r-doc/graphics/plot.default>plot.default</a></code>.</dd>
</dl>

  <h4>Value</h4>

  <p class="rd-p"><dl>
A plot showing the predicted probabilities of the logisitic regression classifier, with a vertical bar
showing the value of the probability threshold, $\tau$.
</dl></p>




<h4>See also</h4>

See <code><a href=#glmnetlrc>glmnetLRC</a></code> for an example.


<h4>Author</h4>

Landon Sego




## lossMatrix

<h3>Build a loss matrix</h3>

<p class="rd-p">Build an arbitrary loss matrix for discrete classification</p>

<h4>Usage</h4>
<pre class="r"><code>lossMatrix(truthLabels, predLabels, lossValues)

printlossMat(x, ...)</code></pre>

<h4>Arguments</h4>
<dl class="rd-dl">
  <dt>truthLabels</dt>
  <dd class="rd-dd">character vector of truth labels</dd>
  <dt>predLabels</dt>
  <dd class="rd-dd">character vector of corresponding predicted labels,
which must be the same length as <code>truthLabels</code></dd>
  <dt>lossValues</dt>
  <dd class="rd-dd">numeric vector of corresponding loss values, which must
be the same length as <code>truthLabels</code> and <code>predLabels</code>.</dd>
  <dt>x</dt>
  <dd class="rd-dd">An object of class <code>lossMat</code></dd>
  <dt>...</dt>
  <dd class="rd-dd">Additional arguments to <code>print.default</code></dd>
</dl>

  <h4>Details</h4>

  <p class="rd-p">This function checks the inputs and binds the three
arguments columnwise into a dataframe.</p>


  <h4>Value</h4>

  <p class="rd-p"><dl>
An object of class <code>lossMat</code>: a dataframe that contains
all the information of the loss matrix to be used by in calculating the loss.
</dl></p>



<h4>Examples</h4>
<pre class="r"><code># A 2x2 symmetric loss matrix
lossMatrix(c("a","a","b","b"), c("a","b","a","b"), c(0, 1, 5, 0))

# A 3x2 asymmetric loss matrix
lossMatrix(rep(letters[1:3], each = 2), rep(letters[4:5], 3),
           c(0, 3, 2, 0, 1, 0))

# An unbalanced loss matrix with a missing element.
# Not sure why one would want to do this.
lossMatrix(c("a","a","b"), c("a","b","b"), c(0, 1, 0))</code></pre>

<h4>Author</h4>

Landon Sego


# Data



## testdata

<h3>Test data set from the Vorbitrap mass spectrometry instrument</h3>


  <h4>Format</h4>

  <p class="rd-p">A dataframe with 99 observations and 96 variables</p>


  <h4>References</h4>

  <p class="rd-p">Amidan BG, Orton DJ, LaMarche BL, Monroe ME, Moore RJ,
Venzin AM, Smith RD, Sego LH, Tardiff MF, Payne SH. 2014.
Signatures for Mass Spectrometry Data Quality.
Journal of Proteome Research. 13(4), 2215-2222.
<a href = http://pubs.acs.org/doi/abs/10.1021/pr401143e>http://pubs.acs.org/doi/abs/10.1021/pr401143e</a></p>



<h4>Examples</h4>
<pre class="r"><code>data(testdata)
str(testdata)</code></pre>



## traindata

<h3>Training data set from the Vorbitrap mass spectrometry instrument</h3>


  <h4>Format</h4>

  <p class="rd-p">A dataframe with 325 observations and 99 variables</p>


  <h4>References</h4>

  <p class="rd-p">Amidan BG, Orton DJ, LaMarche BL, Monroe ME, Moore RJ,
Venzin AM, Smith RD, Sego LH, Tardiff MF, Payne SH. 2014.
Signatures for Mass Spectrometry Data Quality.
Journal of Proteome Research. 13(4), 2215-2222.
<a href = http://pubs.acs.org/doi/abs/10.1021/pr401143e>http://pubs.acs.org/doi/abs/10.1021/pr401143e</a></p>



<h4>Examples</h4>
<pre class="r"><code>data(traindata)
str(traindata)</code></pre>



## glmnetLRC_fit

<h3>A glmnetLRC model fit object</h3>

<p class="rd-p">This object is returned by the call
<code>glmnetLRC_fit <- glmnetLRC(response, predictors, lossMat = lM, estimateLoss = TRUE,
nJobs = parallel::detectCores())</code> in the example of <code><a href='glmnetLRC.html'>glmnetLRC</a></code>. It is preserved
here in the package because it is time consuming to generate.</p>

  <h4>Format</h4>

  <p class="rd-p">A glmnetLRC object returned by <code><a href=#glmnetlrc>glmnetLRC</a></code></p>



<h4>Examples</h4>
<pre class="r"><code># Load fitted glmnetLRC model
data(glmnetLRC_fit)</code></pre>


